{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2445b30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Muhammad\n",
      "[nltk_data]     Swelam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import Embedding\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.layers import LSTM ,SpatialDropout1D\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd0f2b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>txt</th>\n",
       "      <th>dialect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1175358310087892992</td>\n",
       "      <td>بالنهاية ينتفض يغير</td>\n",
       "      <td>IQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1175416117793349632</td>\n",
       "      <td>يعني محسوب البشر حيونه ووحشيه وتطلبون الغرب يح...</td>\n",
       "      <td>IQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1175450108898565888</td>\n",
       "      <td>مبين كلامه خليجي</td>\n",
       "      <td>IQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1175471073770573824</td>\n",
       "      <td>يسلملي مرورك وروحك الحلوه</td>\n",
       "      <td>IQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1175496913145217024</td>\n",
       "      <td>وين الغيبه اخ محمد</td>\n",
       "      <td>IQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                   id  \\\n",
       "0      0  1175358310087892992   \n",
       "1      1  1175416117793349632   \n",
       "2      2  1175450108898565888   \n",
       "3      3  1175471073770573824   \n",
       "4      4  1175496913145217024   \n",
       "\n",
       "                                                 txt dialect  \n",
       "0                                بالنهاية ينتفض يغير      IQ  \n",
       "1  يعني محسوب البشر حيونه ووحشيه وتطلبون الغرب يح...      IQ  \n",
       "2                                   مبين كلامه خليجي      IQ  \n",
       "3                          يسلملي مرورك وروحك الحلوه      IQ  \n",
       "4                                 وين الغيبه اخ محمد      IQ  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv(\"Arabic tweets classification project/clean_data.csv\")\n",
    "df=df.dropna()\n",
    "df.reset_index(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b1e1940",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['txt']\n",
    "y = df['dialect']\n",
    "voc_size=8000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd86d2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "y= label_encoder.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1296ddea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       بالنهاية ينتفض يغير\n",
       "1         يعني محسوب البشر حيونه ووحشيه وتطلبون الغرب يح...\n",
       "2                                          مبين كلامه خليجي\n",
       "3                                 يسلملي مرورك وروحك الحلوه\n",
       "4                                        وين الغيبه اخ محمد\n",
       "                                ...                        \n",
       "457768              لين صبحنا بوجهش زين سعاده مابعدها سعاده\n",
       "457769                                  بالعافيه فقلي الاكل\n",
       "457770                                              مدح يبي\n",
       "457771    ايييي احبها واحب تحتها طاوله للكرك ويفضل بلك ل...\n",
       "457772                      جيبي مطرقه شوفي اهدم واهدم ابوه\n",
       "Name: txt, Length: 457773, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7db19ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "for i in X:\n",
    "    corpus.append(i)\n",
    "    \n",
    "\n",
    "onehot_repr=[one_hot(words,voc_size)for words in corpus] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8e8348f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ... 2338 2986  548]\n",
      " [   0    0    0 ... 7961  841 2452]\n",
      " [   0    0    0 ... 3700  212 1093]\n",
      " ...\n",
      " [   0    0    0 ...    0 1962 2659]\n",
      " [   0    0    0 ... 4060 5641 2548]\n",
      " [   0    0    0 ... 7733 4414  407]]\n"
     ]
    }
   ],
   "source": [
    "sent_length=30\n",
    "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dec2e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 30, 50)            400000    \n",
      "                                                                 \n",
      " spatial_dropout1d (SpatialD  (None, 30, 50)           0         \n",
      " ropout1D)                                                       \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 200)              120800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 18)                3618      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 524,418\n",
      "Trainable params: 524,418\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_vector_features=50\n",
    "model = Sequential()\n",
    "model.add(Embedding(voc_size, embedding_vector_features, input_length=sent_length))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(Dense(18, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3406f046",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final=np.array(embedded_docs)\n",
    "y_final=np.array(y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bff9f793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5723/5723 [==============================] - 352s 61ms/step - loss: 2.2346 - accuracy: 0.2976 - val_loss: 2.0649 - val_accuracy: 0.3543\n",
      "Epoch 2/20\n",
      "5723/5723 [==============================] - 351s 61ms/step - loss: 2.0254 - accuracy: 0.3681 - val_loss: 2.0029 - val_accuracy: 0.3762\n",
      "Epoch 3/20\n",
      "5723/5723 [==============================] - 365s 64ms/step - loss: 1.9572 - accuracy: 0.3898 - val_loss: 1.9849 - val_accuracy: 0.3827\n",
      "Epoch 4/20\n",
      "5723/5723 [==============================] - 357s 62ms/step - loss: 1.9130 - accuracy: 0.4047 - val_loss: 1.9701 - val_accuracy: 0.3880\n",
      "Epoch 5/20\n",
      "5723/5723 [==============================] - 365s 64ms/step - loss: 1.8793 - accuracy: 0.4157 - val_loss: 1.9689 - val_accuracy: 0.3910\n",
      "Epoch 6/20\n",
      "5723/5723 [==============================] - 377s 66ms/step - loss: 1.8523 - accuracy: 0.4241 - val_loss: 1.9642 - val_accuracy: 0.3909\n",
      "Epoch 7/20\n",
      "5723/5723 [==============================] - 418s 73ms/step - loss: 1.8291 - accuracy: 0.4309 - val_loss: 1.9676 - val_accuracy: 0.3914\n",
      "Epoch 8/20\n",
      "5723/5723 [==============================] - 433s 76ms/step - loss: 1.8103 - accuracy: 0.4370 - val_loss: 1.9713 - val_accuracy: 0.3902\n",
      "Epoch 9/20\n",
      "5723/5723 [==============================] - 431s 75ms/step - loss: 1.7933 - accuracy: 0.4411 - val_loss: 1.9740 - val_accuracy: 0.3915\n",
      "Epoch 10/20\n",
      "5723/5723 [==============================] - 452s 79ms/step - loss: 1.7775 - accuracy: 0.4470 - val_loss: 1.9816 - val_accuracy: 0.3928\n",
      "Epoch 11/20\n",
      "5723/5723 [==============================] - 418s 73ms/step - loss: 1.7646 - accuracy: 0.4499 - val_loss: 1.9791 - val_accuracy: 0.3915\n",
      "Epoch 12/20\n",
      "5723/5723 [==============================] - 417s 73ms/step - loss: 1.7543 - accuracy: 0.4540 - val_loss: 1.9883 - val_accuracy: 0.3912\n",
      "Epoch 13/20\n",
      "5723/5723 [==============================] - 421s 74ms/step - loss: 1.7423 - accuracy: 0.4569 - val_loss: 1.9910 - val_accuracy: 0.3907\n",
      "Epoch 14/20\n",
      "5723/5723 [==============================] - 413s 72ms/step - loss: 1.7323 - accuracy: 0.4598 - val_loss: 1.9929 - val_accuracy: 0.3903\n",
      "Epoch 15/20\n",
      "5723/5723 [==============================] - 427s 75ms/step - loss: 1.7262 - accuracy: 0.4613 - val_loss: 2.0078 - val_accuracy: 0.3904\n",
      "Epoch 16/20\n",
      "5723/5723 [==============================] - 403s 70ms/step - loss: 1.7165 - accuracy: 0.4641 - val_loss: 2.0038 - val_accuracy: 0.3909\n",
      "Epoch 17/20\n",
      "5723/5723 [==============================] - 406s 71ms/step - loss: 1.7097 - accuracy: 0.4665 - val_loss: 2.0090 - val_accuracy: 0.3891\n",
      "Epoch 18/20\n",
      "5723/5723 [==============================] - 404s 71ms/step - loss: 1.7031 - accuracy: 0.4685 - val_loss: 2.0152 - val_accuracy: 0.3882\n",
      "Epoch 19/20\n",
      "5723/5723 [==============================] - 378s 66ms/step - loss: 1.6961 - accuracy: 0.4701 - val_loss: 2.0213 - val_accuracy: 0.3881\n",
      "Epoch 20/20\n",
      "5723/5723 [==============================] - 377s 66ms/step - loss: 1.6914 - accuracy: 0.4718 - val_loss: 2.0173 - val_accuracy: 0.3876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21a7a718a00>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=20,batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20d9f65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3876467697012725"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "y_pred=np.argmax(y_pred,axis=1)\n",
    "\n",
    "y_pred=label_encoder.inverse_transform(y_pred)\n",
    "y_test=label_encoder.inverse_transform(y_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix ,classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbc17b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AE       0.30      0.27      0.28      5330\n",
      "          BH       0.24      0.18      0.20      5122\n",
      "          DZ       0.45      0.37      0.40      3261\n",
      "          EG       0.55      0.73      0.63     11591\n",
      "          IQ       0.44      0.32      0.37      3050\n",
      "          JO       0.29      0.23      0.26      5565\n",
      "          KW       0.33      0.41      0.37      8414\n",
      "          LB       0.47      0.49      0.48      5533\n",
      "          LY       0.45      0.48      0.47      7353\n",
      "          MA       0.50      0.45      0.47      2297\n",
      "          OM       0.22      0.19      0.20      3858\n",
      "          PL       0.36      0.41      0.38      8663\n",
      "          QA       0.34      0.35      0.35      6198\n",
      "          SA       0.25      0.26      0.25      5360\n",
      "          SD       0.50      0.40      0.44      2887\n",
      "          SY       0.31      0.22      0.26      3208\n",
      "          TN       0.41      0.31      0.36      1834\n",
      "          YE       0.18      0.08      0.11      2031\n",
      "\n",
      "    accuracy                           0.39     91555\n",
      "   macro avg       0.37      0.34      0.35     91555\n",
      "weighted avg       0.38      0.39      0.38     91555\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
